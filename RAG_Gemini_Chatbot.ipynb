{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARAVINDM12/RAG-GEMINI/blob/main/RAG_Gemini_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Requirements.txt\n"
      ],
      "metadata": {
        "id": "VxuXxKAVRDlz"
      },
      "id": "VxuXxKAVRDlz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "797120dd",
      "metadata": {
        "id": "797120dd"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.3.25 langchain-community==0.3.24 langchain-google-genai==2.1.4 faiss-cpu==1.10.0 pypdf==5.4.0 streamlit==1.44.1 python-dotenv==1.0.1 pyngrok\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting API key(.env file)"
      ],
      "metadata": {
        "id": "e9Uhf9_vRHms"
      },
      "id": "e9Uhf9_vRHms"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f40dc54",
      "metadata": {
        "id": "1f40dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBK6lJFxB6ftsCnLc8gy7F31K3Z709r2NQ\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PDF Processing-splitting pdf into chunks(utils.py)"
      ],
      "metadata": {
        "id": "JvV8ynphROoG"
      },
      "id": "JvV8ynphROoG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68452ea3",
      "metadata": {
        "id": "68452ea3"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "def load_and_split_pdf(pdf_path):\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    docs = loader.load()\n",
        "\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    split_docs = splitter.split_documents(docs)\n",
        "    return split_docs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM Model and Vector Store Creation(rag_chat.py)"
      ],
      "metadata": {
        "id": "pKWz5Df9RWkV"
      },
      "id": "pKWz5Df9RWkV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e40ffbe7",
      "metadata": {
        "id": "e40ffbe7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\", temperature=0.2, google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Embeddings\n",
        "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "def create_vector_store(documents):\n",
        "    return FAISS.from_documents(documents, embedding_model)\n",
        "\n",
        "def build_qa_chain(vectorstore):\n",
        "    retriever = vectorstore.as_retriever()\n",
        "    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)\n",
        "    return qa_chain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Code for Handling PDF Upload and Q&A (main.py)"
      ],
      "metadata": {
        "id": "_PpupjjERaPM"
      },
      "id": "_PpupjjERaPM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29214415",
      "metadata": {
        "id": "29214415"
      },
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tempfile\n",
        "from utils import load_and_split_pdf\n",
        "from rag_chat import create_vector_store, build_qa_chain\n",
        "\n",
        "st.set_page_config(page_title=\"ðŸ“š PDF Q&A Chatbot\")\n",
        "\n",
        "st.title(\"ðŸ“„ Chat with your PDF\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF\", type=\"pdf\")\n",
        "\n",
        "if uploaded_file:\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as tmp:\n",
        "        tmp.write(uploaded_file.read())\n",
        "        tmp_path = tmp.name\n",
        "\n",
        "    with st.spinner(\"Processing document...\"):\n",
        "        docs = load_and_split_pdf(tmp_path)\n",
        "        vectorstore = create_vector_store(docs)\n",
        "        qa_chain = build_qa_chain(vectorstore)\n",
        "        st.success(\"Ready to chat!\")\n",
        "\n",
        "    query = st.text_input(\"Ask a question about the PDF:\")\n",
        "    if query:\n",
        "        result = qa_chain(query)\n",
        "        st.markdown(f\"**Answer:** {result['result']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the app"
      ],
      "metadata": {
        "id": "7u86e_nFRd6_"
      },
      "id": "7u86e_nFRd6_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2723129",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2723129",
        "outputId": "5d4c6c33-a121-4564-ab04-b9bc2127d57a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.91.208.66:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "!streamlit run app.py &\n",
        "\n",
        "# Open tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"ðŸ”— Public URL:\", public_url)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}